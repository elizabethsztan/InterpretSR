{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f935234",
   "metadata": {},
   "source": [
    "# Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92f4a7a",
   "metadata": {},
   "source": [
    "## Wrapping a PyTorch model\n",
    "Create a simple PyTorch model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adc61e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    \"\"\"\n",
    "    Simple MLP.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim, output_dim, hidden_dim):\n",
    "        super(MLP, self).__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(hidden_dim, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.mlp(x)\n",
    "\n",
    "class SimpleModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Simple model class.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim, output_dim, hidden_dim = 64):\n",
    "        super(SimpleModel, self).__init__()\n",
    "\n",
    "        self.mlp = MLP(input_dim, output_dim, hidden_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.mlp(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6941215c",
   "metadata": {},
   "source": [
    "Train the model on some data.\n",
    "\n",
    "$$\n",
    "y = x_0^2 +3 \\sin(x_4)-2\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f363579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the dataset \n",
    "x = np.array([np.random.uniform(0, 1, 10_000) for _ in range(5)]).T  \n",
    "y = x[:, 0]**2 + 3*np.sin(x[:, 4]) - 4\n",
    "noise = np.array([np.random.normal(0, 0.05*np.std(y)) for _ in range(len(y))])\n",
    "y = y + noise "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9fcf89e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up training\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def train_model(model, dataloader, opt, criterion, epochs = 100):\n",
    "    \"\"\"\n",
    "    Train a model for the specified number of epochs.\n",
    "    \n",
    "    Args:\n",
    "        model: PyTorch model to train\n",
    "        dataloader: DataLoader for training data\n",
    "        opt: Optimizer\n",
    "        criterion: Loss function\n",
    "        epochs: Number of training epochs\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (trained_model, loss_tracker)\n",
    "    \"\"\"\n",
    "    loss_tracker = []\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0.0\n",
    "        \n",
    "        for batch_x, batch_y in dataloader:\n",
    "            # Forward pass\n",
    "            pred = model(batch_x)\n",
    "            loss = criterion(pred, batch_y)\n",
    "            \n",
    "            # Backward pass\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "        loss_tracker.append(epoch_loss)\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            avg_loss = epoch_loss / len(dataloader)\n",
    "            print(f'Epoch [{epoch+1}/{epochs}], Avg Loss: {avg_loss:.6f}')\n",
    "    return model, loss_tracker\n",
    "\n",
    "# Instantiate the model\n",
    "model = SimpleModel(input_dim=x.shape[1], output_dim=1)\n",
    "\n",
    "# Set up training\n",
    "criterion = nn.MSELoss()\n",
    "opt = optim.Adam(model.parameters(), lr=0.001)\n",
    "X_train, _, y_train, _ = train_test_split(x, y.reshape(-1,1), test_size=0.2, random_state=290402)\n",
    "\n",
    "# Set up dataset\n",
    "dataset = TensorDataset(torch.FloatTensor(X_train), torch.FloatTensor(y_train))\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "add838bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/20], Avg Loss: 0.091779\n",
      "Epoch [10/20], Avg Loss: 0.065450\n",
      "Epoch [15/20], Avg Loss: 0.048581\n",
      "Epoch [20/20], Avg Loss: 0.038570\n"
     ]
    }
   ],
   "source": [
    "# Train the model and save the weights\n",
    "\n",
    "model, losses = train_model(model, dataloader, opt, criterion, 20)\n",
    "torch.save(model.state_dict(), 'model_weights.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb22ef1",
   "metadata": {},
   "source": [
    "Wrap the mlp layer in the trained model with MLP_SR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77bc4f4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liz/PhD/InterpretSR_project/interpretsr_venv/lib/python3.11/site-packages/juliacall/__init__.py:61: UserWarning: torch was imported before juliacall. This may cause a segfault. To avoid this, import juliacall before importing torch. For updates, see https://github.com/pytorch/pytorch/issues/78829.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected IPython. Loading juliacall extension. See https://juliapy.github.io/PythonCall.jl/stable/compat/#IPython\n"
     ]
    }
   ],
   "source": [
    "from symtorch.mlp_sr import MLP_SR\n",
    "model.mlp = MLP_SR(model.mlp, mlp_name = 'Sequential')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1db5df8",
   "metadata": {},
   "source": [
    "## Interpret the MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca15a8d3",
   "metadata": {},
   "source": [
    "In this example, we pass extra parameters into the `.interpret` method (complexity of operators/constants and parsimony, which is a penalisation of complexity).\\\n",
    "To see all the possible parameters, please see the `PySRRegressor` class from [PySR](https://ai.damtp.cam.ac.uk/pysr/api/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b47775",
   "metadata": {},
   "source": [
    "In this example, we turn verbosity off because we are in a Jupyter notebook. For best performance, run in IPython, as you can terminate the SR any time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d637d376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🛠️ Running SR on output dimension 0 of 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liz/PhD/InterpretSR_project/interpretsr_venv/lib/python3.11/site-packages/pysr/sr.py:2811: UserWarning: Note: it looks like you are running in Jupyter. The progress bar will be turned off.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💡Best equation for output 0 found to be ((x0 * x0) * 0.9140018) + inv(((x4 * (x4 + 0.80192065)) + 1.2257804) * -0.2080118).\n",
      "❤️ SR on Sequential complete.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: PySRRegressor.equations_ = [\n",
       " \t    pick     score                                           equation  \\\n",
       " \t0         0.000000                                                 x4   \n",
       " \t1         2.694948                                          -2.320417   \n",
       " \t2         0.421408                                     x4 + -2.826031   \n",
       " \t3         0.479556                             x4 + (x4 + -3.3315902)   \n",
       " \t4         0.137519                      (x4 + -1.4832371) * 2.3734488   \n",
       " \t5         1.247076                      ((x0 + x4) + x4) + -3.8293786   \n",
       " \t6         0.775753                 (x0 + (x4 * 2.382997)) + -4.023018   \n",
       " \t7         0.231667        ((x4 * 2.3833776) + -3.8567781) + (x0 * x0)   \n",
       " \t8         0.059380          (sin(x4) * 2.7949803) + (x0 + -4.1155796)   \n",
       " \t9         0.496750     (x0 * x0) + ((sin(x4) * 2.795451) + -3.949366)   \n",
       " \t10        0.039731  (inv(x4 + ((x4 * x4) + 1.3869555)) * -5.523348...   \n",
       " \t11        0.211374  ((x0 * 0.9184323) * x0) + ((sin(x4) + -1.40345...   \n",
       " \t12        0.043970  inv(((x4 + (x4 * x4)) + 1.3675728) * -0.184817...   \n",
       " \t13  >>>>  0.080072  ((x0 * x0) * 0.9140018) + inv(((x4 * (x4 + 0.8...   \n",
       " \t14        0.013895  (sin(x0 * x0) + -3.9381435) + (x4 * ((((x4 * x...   \n",
       " \t15        0.028643  (((((x4 * x4) * -0.5653208) + 2.7596562) * x4)...   \n",
       " \t16        0.039183  (((sin(x0) * x0) + -3.7143936) + (x4 * (((x4 *...   \n",
       " \t17        0.077830  (sin(((x0 * x0) * -0.19770725) + (x4 * (((x4 *...   \n",
       " \t18        0.062228  (sin((x0 * (x0 * -0.20015873)) + ((((x4 * 0.08...   \n",
       " \t\n",
       " \t        loss  complexity  \n",
       " \t0   8.225475           1  \n",
       " \t1   0.555597           2  \n",
       " \t2   0.239183           4  \n",
       " \t3   0.091663           6  \n",
       " \t4   0.079886           7  \n",
       " \t5   0.022955           8  \n",
       " \t6   0.010567           9  \n",
       " \t7   0.006649          11  \n",
       " \t8   0.006265          12  \n",
       " \t9   0.002320          14  \n",
       " \t10  0.002143          16  \n",
       " \t11  0.001734          17  \n",
       " \t12  0.001588          19  \n",
       " \t13  0.001466          20  \n",
       " \t14  0.001406          23  \n",
       " \t15  0.001367          24  \n",
       " \t16  0.001264          26  \n",
       " \t17  0.001169          27  \n",
       " \t18  0.001032          29  \n",
       " ]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.mlp.interpret(torch.FloatTensor(X_train), \n",
    "                       niterations = 500, # Should set to higher\n",
    "                       verbosity=0, \n",
    "                       complexity_of_operators = {\"sin\":3, \"exp\":3}, \n",
    "                       complexity_of_constants = 2,\n",
    "                       parsimony = 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8275ed6e",
   "metadata": {},
   "source": [
    "See the full Pareto front of equations. The best equation is chosen as a balance of accuracy and complexity.\\\n",
    "Outputs from *PySR* are saved in `SR_output/MLP_name`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31109683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: PySRRegressor.equations_ = [\n",
      "\t    pick     score                                           equation  \\\n",
      "\t0         0.000000                                                 x4   \n",
      "\t1         2.694948                                          -2.320417   \n",
      "\t2         0.421408                                     x4 + -2.826031   \n",
      "\t3         0.479556                             x4 + (x4 + -3.3315902)   \n",
      "\t4         0.137519                      (x4 + -1.4832371) * 2.3734488   \n",
      "\t5         1.247076                      ((x0 + x4) + x4) + -3.8293786   \n",
      "\t6         0.775753                 (x0 + (x4 * 2.382997)) + -4.023018   \n",
      "\t7         0.231667        ((x4 * 2.3833776) + -3.8567781) + (x0 * x0)   \n",
      "\t8         0.059380          (sin(x4) * 2.7949803) + (x0 + -4.1155796)   \n",
      "\t9         0.496750     (x0 * x0) + ((sin(x4) * 2.795451) + -3.949366)   \n",
      "\t10        0.039731  (inv(x4 + ((x4 * x4) + 1.3869555)) * -5.523348...   \n",
      "\t11        0.211374  ((x0 * 0.9184323) * x0) + ((sin(x4) + -1.40345...   \n",
      "\t12        0.043970  inv(((x4 + (x4 * x4)) + 1.3675728) * -0.184817...   \n",
      "\t13  >>>>  0.080072  ((x0 * x0) * 0.9140018) + inv(((x4 * (x4 + 0.8...   \n",
      "\t14        0.013895  (sin(x0 * x0) + -3.9381435) + (x4 * ((((x4 * x...   \n",
      "\t15        0.028643  (((((x4 * x4) * -0.5653208) + 2.7596562) * x4)...   \n",
      "\t16        0.039183  (((sin(x0) * x0) + -3.7143936) + (x4 * (((x4 *...   \n",
      "\t17        0.077830  (sin(((x0 * x0) * -0.19770725) + (x4 * (((x4 *...   \n",
      "\t18        0.062228  (sin((x0 * (x0 * -0.20015873)) + ((((x4 * 0.08...   \n",
      "\t\n",
      "\t        loss  complexity  \n",
      "\t0   8.225475           1  \n",
      "\t1   0.555597           2  \n",
      "\t2   0.239183           4  \n",
      "\t3   0.091663           6  \n",
      "\t4   0.079886           7  \n",
      "\t5   0.022955           8  \n",
      "\t6   0.010567           9  \n",
      "\t7   0.006649          11  \n",
      "\t8   0.006265          12  \n",
      "\t9   0.002320          14  \n",
      "\t10  0.002143          16  \n",
      "\t11  0.001734          17  \n",
      "\t12  0.001588          19  \n",
      "\t13  0.001466          20  \n",
      "\t14  0.001406          23  \n",
      "\t15  0.001367          24  \n",
      "\t16  0.001264          26  \n",
      "\t17  0.001169          27  \n",
      "\t18  0.001032          29  \n",
      "]}\n"
     ]
    }
   ],
   "source": [
    "print(model.mlp.pysr_regressor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db788500",
   "metadata": {},
   "source": [
    "## Switch to Using the Equation Instead in the Forwards Pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2dbf360",
   "metadata": {},
   "source": [
    "You can choose the equation you want to switch to by choosing the desired complexity of equation. \\\n",
    "If left blank, then we choose the best equation chosen by *PySR*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "abef72c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Successfully switched Sequential to symbolic equations for all 1 dimensions:\n",
      "   Dimension 0: (x0 * x0) + ((sin(x4) * 2.795451) + -3.949366)\n",
      "   Variables: ['x0', 'x4']\n",
      "🎯 All 1 output dimensions now using symbolic equations.\n"
     ]
    }
   ],
   "source": [
    "model.mlp.switch_to_equation(complexity=14) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e7cfd0",
   "metadata": {},
   "source": [
    "Now when running the forwards pass through the model, it uses the symbolic equation instead of the MLP. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e526154f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-3.8636],\n",
       "        [-3.4790],\n",
       "        [-1.5592],\n",
       "        ...,\n",
       "        [-2.7508],\n",
       "        [-2.6754],\n",
       "        [-3.3049]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpretable_outputs = model(torch.tensor(X_train, dtype=torch.float32))\n",
    "interpretable_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5835dd8e",
   "metadata": {},
   "source": [
    "## Switch to Using the MLP in the Forwards Pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "34291a48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Switched Sequential back to MLP\n"
     ]
    }
   ],
   "source": [
    "mlp_outputs = model.mlp.switch_to_mlp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "79e43dc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-3.8313],\n",
       "        [-3.5179],\n",
       "        [-1.5196],\n",
       "        ...,\n",
       "        [-2.7176],\n",
       "        [-2.6945],\n",
       "        [-3.3658]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    model_outputs = model.mlp(torch.tensor(X_train, dtype=torch.float32))\n",
    "model_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e0c6c463",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8000, 1])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0e258b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up \n",
    "import os\n",
    "import shutil\n",
    "if os.path.exists('SR_output'):\n",
    "    shutil.rmtree('SR_output')\n",
    "os.remove('model_weights.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3434c7db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "interpretsr_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
