

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="./">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>API Reference &mdash; SymTorch 1.0.0 documentation</title>
      <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="_static/mystnb.8ecb98da25f57f5357bf6f572d296f466b2cfe2517ffebfabe82451661e28f02.css" />

  
      <script src="_static/jquery.js?v=5d32c60e"></script>
      <script src="_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="_static/documentation_options.js?v=8d563738"></script>
      <script src="_static/doctools.js?v=9bcbadda"></script>
      <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Getting Started" href="demos/getting_started_demo.html" />
    <link rel="prev" title="Installation" href="index.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="index.html" class="icon icon-home">
            SymTorch
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Documentation:</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">API Reference</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#mlp-sr">MLP_SR</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#symtorch.mlp_sr.MLP_SR"><code class="docutils literal notranslate"><span class="pre">MLP_SR</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#symtorch.mlp_sr.MLP_SR.InterpretSR_MLP"><code class="docutils literal notranslate"><span class="pre">MLP_SR.InterpretSR_MLP</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#symtorch.mlp_sr.MLP_SR.mlp_name"><code class="docutils literal notranslate"><span class="pre">MLP_SR.mlp_name</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#symtorch.mlp_sr.MLP_SR.pysr_regressor"><code class="docutils literal notranslate"><span class="pre">MLP_SR.pysr_regressor</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#symtorch.mlp_sr.MLP_SR.__init__"><code class="docutils literal notranslate"><span class="pre">MLP_SR.__init__()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#symtorch.mlp_sr.MLP_SR.forward"><code class="docutils literal notranslate"><span class="pre">MLP_SR.forward()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#symtorch.mlp_sr.MLP_SR.interpret"><code class="docutils literal notranslate"><span class="pre">MLP_SR.interpret()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#symtorch.mlp_sr.MLP_SR.switch_to_equation"><code class="docutils literal notranslate"><span class="pre">MLP_SR.switch_to_equation()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#symtorch.mlp_sr.MLP_SR.switch_to_mlp"><code class="docutils literal notranslate"><span class="pre">MLP_SR.switch_to_mlp()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#pruning-mlp">Pruning_MLP</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#symtorch.toolkit.Pruning_MLP"><code class="docutils literal notranslate"><span class="pre">Pruning_MLP</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#symtorch.toolkit.Pruning_MLP.InterpretSR_MLP"><code class="docutils literal notranslate"><span class="pre">Pruning_MLP.InterpretSR_MLP</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#symtorch.toolkit.Pruning_MLP.mlp_name"><code class="docutils literal notranslate"><span class="pre">Pruning_MLP.mlp_name</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#symtorch.toolkit.Pruning_MLP.pysr_regressor"><code class="docutils literal notranslate"><span class="pre">Pruning_MLP.pysr_regressor</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#symtorch.toolkit.Pruning_MLP.initial_dim"><code class="docutils literal notranslate"><span class="pre">Pruning_MLP.initial_dim</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#symtorch.toolkit.Pruning_MLP.current_dim"><code class="docutils literal notranslate"><span class="pre">Pruning_MLP.current_dim</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#symtorch.toolkit.Pruning_MLP.target_dim"><code class="docutils literal notranslate"><span class="pre">Pruning_MLP.target_dim</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#symtorch.toolkit.Pruning_MLP.pruning_schedule"><code class="docutils literal notranslate"><span class="pre">Pruning_MLP.pruning_schedule</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#symtorch.toolkit.Pruning_MLP.pruning_mask"><code class="docutils literal notranslate"><span class="pre">Pruning_MLP.pruning_mask</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#symtorch.toolkit.Pruning_MLP.__init__"><code class="docutils literal notranslate"><span class="pre">Pruning_MLP.__init__()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#symtorch.toolkit.Pruning_MLP.set_schedule"><code class="docutils literal notranslate"><span class="pre">Pruning_MLP.set_schedule()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#symtorch.toolkit.Pruning_MLP.prune"><code class="docutils literal notranslate"><span class="pre">Pruning_MLP.prune()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#symtorch.toolkit.Pruning_MLP.get_active_dimensions"><code class="docutils literal notranslate"><span class="pre">Pruning_MLP.get_active_dimensions()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#symtorch.toolkit.Pruning_MLP.interpret"><code class="docutils literal notranslate"><span class="pre">Pruning_MLP.interpret()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#symtorch.toolkit.Pruning_MLP.switch_to_equation"><code class="docutils literal notranslate"><span class="pre">Pruning_MLP.switch_to_equation()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#symtorch.toolkit.Pruning_MLP.forward"><code class="docutils literal notranslate"><span class="pre">Pruning_MLP.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#configuration-and-parameters">Configuration and Parameters</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#pysr-parameters">PySR Parameters</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Demos:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="demos/getting_started_demo.html">Getting Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="demos/toolkit_demo.html">SymTorch Toolkit: Pruning</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">SymTorch</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">API Reference</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/api_reference.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="api-reference">
<h1>API Reference<a class="headerlink" href="#api-reference" title="Link to this heading"></a></h1>
<p>This section contains the complete API reference for SymTorch.</p>
<section id="mlp-sr">
<h2>MLP_SR<a class="headerlink" href="#mlp-sr" title="Link to this heading"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="symtorch.mlp_sr.MLP_SR">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">symtorch.mlp_sr.</span></span><span class="sig-name descname"><span class="pre">MLP_SR</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mlp</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch v2.7)"><span class="pre">Module</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">mlp_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/symtorch/mlp_sr.html#MLP_SR"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#symtorch.mlp_sr.MLP_SR" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch v2.7)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></a></p>
<p>A PyTorch module wrapper that adds symbolic regression capabilities to MLPs.</p>
<p>This class wraps any PyTorch MLP (Multi-Layer Perceptron) and provides methods
to discover symbolic expressions that approximate the learned neural network
behavior using genetic algorithms supported by PySR.</p>
<p>The wrapper maintains full compatibility with PyTorch’s training pipeline while
adding interpretability features through symbolic regression.</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="symtorch.mlp_sr.MLP_SR.InterpretSR_MLP">
<span class="sig-name descname"><span class="pre">InterpretSR_MLP</span></span><a class="headerlink" href="#symtorch.mlp_sr.MLP_SR.InterpretSR_MLP" title="Link to this definition"></a></dt>
<dd><p>The wrapped PyTorch MLP model</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>nn.Module</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="symtorch.mlp_sr.MLP_SR.mlp_name">
<span class="sig-name descname"><span class="pre">mlp_name</span></span><a class="headerlink" href="#symtorch.mlp_sr.MLP_SR.mlp_name" title="Link to this definition"></a></dt>
<dd><p>Human-readable name for the MLP instance</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)">str</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="symtorch.mlp_sr.MLP_SR.pysr_regressor">
<span class="sig-name descname"><span class="pre">pysr_regressor</span></span><a class="headerlink" href="#symtorch.mlp_sr.MLP_SR.pysr_regressor" title="Link to this definition"></a></dt>
<dd><p>The fitted symbolic regression model</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>PySRRegressor</p>
</dd>
</dl>
</dd></dl>

<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">interpretsr.mlp_sr</span><span class="w"> </span><span class="kn">import</span> <span class="n">MLP_SR</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Create a model</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span><span class="w"> </span><span class="nc">SimpleModel</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="go">        def __init__(self, input_dim, output_dim, hidden_dim = 64):</span>
<span class="go">            super(SimpleModel, self).__init__()</span>
<span class="go">            mlp = nn.Sequential(</span>
<span class="go">                nn.Linear(input_dim, hidden_dim),</span>
<span class="go">                nn.ReLU(),</span>
<span class="go">                nn.Dropout(0.2),</span>
<span class="go">                nn.Linear(hidden_dim, hidden_dim),</span>
<span class="go">                nn.ReLU(),</span>
<span class="go">                nn.Dropout(0.2),</span>
<span class="go">                nn.Linear(hidden_dim, hidden_dim),</span>
<span class="go">                nn.ReLU(),</span>
<span class="go">                nn.Dropout(0.2),</span>
<span class="go">                nn.Linear(hidden_dim, output_dim)</span>
<span class="go">            )</span>
<span class="go">            self.mlp = mlp</span>
<span class="go">            with MLP_SR and provide a label</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">SimpleModel</span><span class="p">(</span><span class="n">input_dim</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">output_dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># Initialise the model</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Train the model normally</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">training_function</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">,</span> <span class="n">num_steps</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Wrap the mlp with the MLP_SR wrapper</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">mlp</span> <span class="o">=</span> <span class="n">MLP_SR</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">mlp</span><span class="p">,</span> <span class="n">mlp_name</span> <span class="o">=</span> <span class="s2">&quot;Sequential&quot;</span><span class="p">)</span> <span class="c1"># Wrap the mlp</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Apply symbolic regression to the inputs and outputs of the MLP</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">regressor</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">mlp</span><span class="o">.</span><span class="n">interpret</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Switch to using the symbolic equation instead of the MLP in the forwards</span>
<span class="go">    pass of your deep learning model</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">switch_to_equation</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Switch back to using the MLP in the forwards pass</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">switch_to_mlp</span><span class="p">()</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>mlp</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch v2.7)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></a></span>)</p></li>
<li><p><strong>mlp_name</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a></span>)</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="symtorch.mlp_sr.MLP_SR.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mlp</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch v2.7)"><span class="pre">Module</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">mlp_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/symtorch/mlp_sr.html#MLP_SR.__init__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#symtorch.mlp_sr.MLP_SR.__init__" title="Link to this definition"></a></dt>
<dd><p>Initialise the MLP_SR wrapper.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>mlp</strong> (<em>nn.Module</em>) – The PyTorch MLP model to wrap</p></li>
<li><p><strong>mlp_name</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><em>optional</em>) – Human-readable name for this MLP instance.
If None, generates a unique name based on object ID.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="symtorch.mlp_sr.MLP_SR.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/symtorch/mlp_sr.html#MLP_SR.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#symtorch.mlp_sr.MLP_SR.forward" title="Link to this definition"></a></dt>
<dd><p>Forward pass through the model.</p>
<p>Automatically switches between MLP and symbolic equations based on current mode.
When using symbolic equation mode, evaluates each output dimension separately
using its corresponding symbolic expression.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> (<a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.7)"><em>torch.Tensor</em></a>) – Input tensor of shape (batch_size, input_dim)</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Output tensor of shape (batch_size, output_dim)</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.7)">torch.Tensor</a></p>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#ValueError" title="(in Python v3.13)"><strong>ValueError</strong></a> – If symbolic equations require variables not present in input</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="symtorch.mlp_sr.MLP_SR.interpret">
<span class="sig-name descname"><span class="pre">interpret</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_dim</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><span class="pre">int</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">parent_model</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/symtorch/mlp_sr.html#MLP_SR.interpret"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#symtorch.mlp_sr.MLP_SR.interpret" title="Link to this definition"></a></dt>
<dd><p>Discover symbolic expressions that approximate the MLP’s behavior.</p>
<p>Uses PySR to find mathematical expressions that best fit the input-output relationship learned by the neural network.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> (<a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.7)"><em>torch.Tensor</em></a>) – Input data for symbolic regression fitting</p></li>
<li><p><strong>output_dim</strong> (<a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.7)"><em>torch.Tensor</em></a>) – The output dimension to run PySR on. If None, PySR run on all outputs. Default: None.</p></li>
<li><p><strong>parent_model</strong> (<em>nn.Module</em><em>, </em><em>optional</em>) – The parent model containing this MLP_SR instance.
If provided, will trace intermediate activations to get
the actual inputs/outputs at this layer level.</p></li>
<li><p><strong>**kwargs</strong> – Parameters passed to PySRRegressor. Defaults:
- binary_operators (list): [“+”, “*”]
- unary_operators (list): [“inv(x) = 1/x”, “sin”, “exp”]
- niterations (int): 400
- output_directory (str): “SR_output/{mlp_name}” # Where PySR outputs are
stored
- run_id (str): “{timestamp}” # Where PySR outputs of a specific run
are stored</p></li>
<li><p><strong>PySRRegressor</strong> (<em>To see more information on the possible inputs to the</em>)</p></li>
<li><p><strong>see</strong> (<em>please</em>)</p></li>
<li><p><strong>documentation.</strong> (<em>the PySR</em>)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Fitted symbolic regression model</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>PySRRegressor</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">regressor</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">interpret</span><span class="p">(</span><span class="n">train_inputs</span><span class="p">,</span> <span class="n">niterations</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">regressor</span><span class="o">.</span><span class="n">get_best</span><span class="p">()[</span><span class="s1">&#39;equation&#39;</span><span class="p">])</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="symtorch.mlp_sr.MLP_SR.switch_to_equation">
<span class="sig-name descname"><span class="pre">switch_to_equation</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">complexity</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)"><span class="pre">list</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/symtorch/mlp_sr.html#MLP_SR.switch_to_equation"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#symtorch.mlp_sr.MLP_SR.switch_to_equation" title="Link to this definition"></a></dt>
<dd><p>Switch the forward pass from MLP to symbolic equations for all output dimensions.</p>
<p>After calling this method, the model will use the discovered symbolic
expressions instead of the neural network for forward passes. This requires
equations to be available for ALL output dimensions.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>complexity</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)"><em>list</em></a><em>, </em><em>optional</em>) – Specific complexity levels to use for each dimension.
If None, uses the best overall equation for each dimension.</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">switch_to_equation</span><span class="p">(</span><span class="n">complexity</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="symtorch.mlp_sr.MLP_SR.switch_to_mlp">
<span class="sig-name descname"><span class="pre">switch_to_mlp</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/symtorch/mlp_sr.html#MLP_SR.switch_to_mlp"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#symtorch.mlp_sr.MLP_SR.switch_to_mlp" title="Link to this definition"></a></dt>
<dd><p>Switch back to using the original MLP for forward passes.</p>
<p>Restores the neural network as the primary forward pass mechanism,
reverting any previous switch_to_equation() call.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>True if switch was successful, False if no original MLP stored</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)">bool</a></p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">switch_to_equation</span><span class="p">()</span>  <span class="c1"># Use symbolic equation</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># ... do some analysis ...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">switch_to_mlp</span><span class="p">()</span>       <span class="c1"># Switch back to neural network</span>
</pre></div>
</div>
</dd></dl>

</dd></dl>

</section>
<section id="pruning-mlp">
<h2>Pruning_MLP<a class="headerlink" href="#pruning-mlp" title="Link to this heading"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="symtorch.toolkit.Pruning_MLP">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">symtorch.toolkit.</span></span><span class="sig-name descname"><span class="pre">Pruning_MLP</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mlp</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch v2.7)"><span class="pre">Module</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">initial_dim</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><span class="pre">int</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_dim</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><span class="pre">int</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">mlp_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/symtorch/toolkit.html#Pruning_MLP"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#symtorch.toolkit.Pruning_MLP" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#symtorch.mlp_sr.MLP_SR" title="symtorch.mlp_sr.MLP_SR"><code class="xref py py-class docutils literal notranslate"><span class="pre">MLP_SR</span></code></a></p>
<p>A PyTorch module wrapper that adds dynamic pruning and symbolic regression capabilities to MLPs.</p>
<p>This class extends MLP_SR to provide progressive dimensionality reduction through pruning
while maintaining interpretability features. It dynamically removes less important output
dimensions during training based on activation variance, then applies symbolic regression
to the remaining active dimensions.</p>
<p>The wrapper maintains full compatibility with PyTorch’s training pipeline and inherits
all MLP_SR functionality for symbolic regression on pruned dimensions.</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="symtorch.toolkit.Pruning_MLP.InterpretSR_MLP">
<span class="sig-name descname"><span class="pre">InterpretSR_MLP</span></span><a class="headerlink" href="#symtorch.toolkit.Pruning_MLP.InterpretSR_MLP" title="Link to this definition"></a></dt>
<dd><p>The wrapped PyTorch MLP model (inherited from MLP_SR)</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>nn.Module</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="symtorch.toolkit.Pruning_MLP.mlp_name">
<span class="sig-name descname"><span class="pre">mlp_name</span></span><a class="headerlink" href="#symtorch.toolkit.Pruning_MLP.mlp_name" title="Link to this definition"></a></dt>
<dd><p>Human-readable name for the MLP instance (inherited from MLP_SR)</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)">str</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="symtorch.toolkit.Pruning_MLP.pysr_regressor">
<span class="sig-name descname"><span class="pre">pysr_regressor</span></span><a class="headerlink" href="#symtorch.toolkit.Pruning_MLP.pysr_regressor" title="Link to this definition"></a></dt>
<dd><p>Dictionary mapping active dimensions to fitted symbolic regression models (inherited from MLP_SR)</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.13)">dict</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="symtorch.toolkit.Pruning_MLP.initial_dim">
<span class="sig-name descname"><span class="pre">initial_dim</span></span><a class="headerlink" href="#symtorch.toolkit.Pruning_MLP.initial_dim" title="Link to this definition"></a></dt>
<dd><p>Initial output dimensionality before pruning</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)">int</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="symtorch.toolkit.Pruning_MLP.current_dim">
<span class="sig-name descname"><span class="pre">current_dim</span></span><a class="headerlink" href="#symtorch.toolkit.Pruning_MLP.current_dim" title="Link to this definition"></a></dt>
<dd><p>Current number of active dimensions</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)">int</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="symtorch.toolkit.Pruning_MLP.target_dim">
<span class="sig-name descname"><span class="pre">target_dim</span></span><a class="headerlink" href="#symtorch.toolkit.Pruning_MLP.target_dim" title="Link to this definition"></a></dt>
<dd><p>Final target dimensionality after pruning</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)">int</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="symtorch.toolkit.Pruning_MLP.pruning_schedule">
<span class="sig-name descname"><span class="pre">pruning_schedule</span></span><a class="headerlink" href="#symtorch.toolkit.Pruning_MLP.pruning_schedule" title="Link to this definition"></a></dt>
<dd><p>Mapping from epoch to target dimensions</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.13)">dict</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="symtorch.toolkit.Pruning_MLP.pruning_mask">
<span class="sig-name descname"><span class="pre">pruning_mask</span></span><a class="headerlink" href="#symtorch.toolkit.Pruning_MLP.pruning_mask" title="Link to this definition"></a></dt>
<dd><p>Boolean mask indicating active dimensions</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.7)">torch.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">symtorch.toolkit</span><span class="w"> </span><span class="kn">import</span> <span class="n">Pruning_MLP</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Create a composite model</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span><span class="w"> </span><span class="nc">SimpleModel</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_dim</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">,</span> <span class="n">output_dim_f</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="o">=</span><span class="mi">128</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">(</span><span class="n">SimpleModel</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">f_net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
<span class="gp">... </span>            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">input_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">),</span>
<span class="gp">... </span>            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
<span class="gp">... </span>            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">output_dim_f</span><span class="p">)</span>
<span class="gp">... </span>        <span class="p">)</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">g_net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">output_dim_f</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">)</span>
<span class="gp">...</span>
<span class="gp">... </span>    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="gp">... </span>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">f_net</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="gp">... </span>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">g_net</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="n">x</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Create model and wrap f_net with pruning</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">SimpleModel</span><span class="p">(</span><span class="n">input_dim</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">output_dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">output_dim_f</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">f_net</span> <span class="o">=</span> <span class="n">Pruning_MLP</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">f_net</span><span class="p">,</span>
<span class="gp">... </span>                         <span class="n">initial_dim</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span>
<span class="gp">... </span>                         <span class="n">target_dim</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
<span class="gp">... </span>                         <span class="n">mlp_name</span><span class="o">=</span><span class="s2">&quot;f_net&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Set up pruning schedule</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">epochs</span> <span class="o">=</span> <span class="mi">100</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">f_net</span><span class="o">.</span><span class="n">set_schedule</span><span class="p">(</span><span class="n">total_epochs</span><span class="o">=</span><span class="n">epochs</span><span class="p">,</span> <span class="n">end_epoch_frac</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># During training loop</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
<span class="gp">... </span>    <span class="c1"># ... training code ...</span>
<span class="gp">... </span>    <span class="n">model</span><span class="o">.</span><span class="n">f_net</span><span class="o">.</span><span class="n">prune</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">validation_data</span><span class="p">)</span>  <span class="c1"># Prune based on importance</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Apply symbolic regression to active dimensions only</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">regressor</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">f_net</span><span class="o">.</span><span class="n">interpret</span><span class="p">(</span><span class="n">train_inputs</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Switch to using symbolic equations for active dimensions</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">f_net</span><span class="o">.</span><span class="n">switch_to_equation</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Switch back to using the MLP</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">f_net</span><span class="o">.</span><span class="n">switch_to_mlp</span><span class="p">()</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>mlp</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch v2.7)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></a></span>)</p></li>
<li><p><strong>initial_dim</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a></span>)</p></li>
<li><p><strong>target_dim</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a></span>)</p></li>
<li><p><strong>mlp_name</strong> (<span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a></span>)</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="symtorch.toolkit.Pruning_MLP.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mlp</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch v2.7)"><span class="pre">Module</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">initial_dim</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><span class="pre">int</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_dim</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><span class="pre">int</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">mlp_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/symtorch/toolkit.html#Pruning_MLP.__init__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#symtorch.toolkit.Pruning_MLP.__init__" title="Link to this definition"></a></dt>
<dd><p>Initialise the Pruning_MLP wrapper.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>mlp</strong> (<em>nn.Module</em>) – The PyTorch MLP model to wrap</p></li>
<li><p><strong>initial_dim</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – Initial output dimensionality before pruning</p></li>
<li><p><strong>target_dim</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – Target output dimensionality after pruning</p></li>
<li><p><strong>mlp_name</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><em>optional</em>) – Human-readable name for this MLP instance.
If None, generates a unique name based on object ID.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="symtorch.toolkit.Pruning_MLP.set_schedule">
<span class="sig-name descname"><span class="pre">set_schedule</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">total_epochs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><span class="pre">int</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">decay_rate</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'cosine'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">end_epoch_frac</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><span class="pre">float</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.5</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/symtorch/toolkit.html#Pruning_MLP.set_schedule"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#symtorch.toolkit.Pruning_MLP.set_schedule" title="Link to this definition"></a></dt>
<dd><p>Set up the pruning schedule for progressive dimensionality reduction.</p>
<p>Creates a schedule that progressively reduces dimensions from initial_dim to target_dim
over the specified fraction of training epochs using the chosen decay strategy.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>total_epochs</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – Total number of training epochs</p></li>
<li><p><strong>decay_rate</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><em>optional</em>) – Pruning schedule type. Options:
- ‘cosine’: Cosine annealing schedule (default)
- ‘linear’: Linear reduction schedule
- ‘exp’: Exponential decay schedule</p></li>
<li><p><strong>end_epoch_frac</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>, </em><em>optional</em>) – Fraction of total epochs to complete pruning by.
Defaults to 0.5 (pruning ends halfway through training)</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">pruned_mlp</span><span class="o">.</span><span class="n">set_schedule</span><span class="p">(</span><span class="n">total_epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">decay_rate</span><span class="o">=</span><span class="s1">&#39;cosine&#39;</span><span class="p">,</span> <span class="n">end_epoch_frac</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="symtorch.toolkit.Pruning_MLP.prune">
<span class="sig-name descname"><span class="pre">prune</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">epoch</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><span class="pre">int</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_data</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.7)"><span class="pre">Tensor</span></a></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/symtorch/toolkit.html#Pruning_MLP.prune"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#symtorch.toolkit.Pruning_MLP.prune" title="Link to this definition"></a></dt>
<dd><p>Perform pruning for the current epoch based on the pruning schedule.</p>
<p>Evaluates the importance of each output dimension by computing the standard deviation
of activations across the sample data. Retains the most important dimensions according
to the current epoch’s target dimensionality.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>epoch</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – Current training epoch</p></li>
<li><p><strong>sample_data</strong> (<a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.7)"><em>torch.Tensor</em></a>) – Sample input data to evaluate dimension importance.
Typically a subset of validation data.</p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This method should be called during each training epoch. If the current epoch
is not in the pruning schedule, no pruning is performed.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="symtorch.toolkit.Pruning_MLP.get_active_dimensions">
<span class="sig-name descname"><span class="pre">get_active_dimensions</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/symtorch/toolkit.html#Pruning_MLP.get_active_dimensions"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#symtorch.toolkit.Pruning_MLP.get_active_dimensions" title="Link to this definition"></a></dt>
<dd><p>Get indices of currently active (non-masked) dimensions.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><dl class="simple">
<dt>List of integer indices for dimensions that are currently active</dt><dd><p>(not pruned/masked)</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)">list</a></p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">active_dims</span> <span class="o">=</span> <span class="n">pruned_mlp</span><span class="o">.</span><span class="n">get_active_dimensions</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Active dimensions: </span><span class="si">{</span><span class="n">active_dims</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="go">Active dimensions: [5, 12, 18]</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="symtorch.toolkit.Pruning_MLP.interpret">
<span class="sig-name descname"><span class="pre">interpret</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sample_data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">parent_model</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">pysr_kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/symtorch/toolkit.html#Pruning_MLP.interpret"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#symtorch.toolkit.Pruning_MLP.interpret" title="Link to this definition"></a></dt>
<dd><p>Discover symbolic expressions for active (non-pruned) dimensions only.</p>
<p>Overrides MLP_SR’s interpret method to focus symbolic regression on dimensions
that survived the pruning process, ignoring inactive/masked dimensions.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>sample_data</strong> (<a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.7)"><em>torch.Tensor</em></a><em> or </em><em>DataLoader</em>) – Input data for symbolic regression fitting.
Can be tensor or DataLoader for batched processing.</p></li>
<li><p><strong>parent_model</strong> (<em>nn.Module</em><em>, </em><em>optional</em>) – The parent model containing this Pruning_MLP instance.
If provided, will trace intermediate activations to get
the actual inputs/outputs at this layer level.</p></li>
<li><p><strong>**pysr_kwargs</strong> – Parameters passed to PySRRegressor. Inherits same defaults as MLP_SR:
- binary_operators (list): [“+”, “*”]
- unary_operators (list): [“inv(x) = 1/x”, “sin”, “exp”]
- niterations (int): 400
- output_directory (str): “SR_output/{mlp_name}”
- run_id (str): “dim{dim_idx}_{timestamp}”</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Dictionary mapping active dimension indices to fitted PySRRegressor objects</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.13)">dict</a></p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">regressors</span> <span class="o">=</span> <span class="n">pruned_mlp</span><span class="o">.</span><span class="n">interpret</span><span class="p">(</span><span class="n">train_data</span><span class="p">,</span> <span class="n">niterations</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">dim_idx</span><span class="p">,</span> <span class="n">regressor</span> <span class="ow">in</span> <span class="n">regressors</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Dimension </span><span class="si">{</span><span class="n">dim_idx</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">regressor</span><span class="o">.</span><span class="n">get_best</span><span class="p">()[</span><span class="s1">&#39;equation&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="symtorch.toolkit.Pruning_MLP.switch_to_equation">
<span class="sig-name descname"><span class="pre">switch_to_equation</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">complexity</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)"><span class="pre">list</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/symtorch/toolkit.html#Pruning_MLP.switch_to_equation"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#symtorch.toolkit.Pruning_MLP.switch_to_equation" title="Link to this definition"></a></dt>
<dd><p>Switch forward pass to use symbolic equations for active dimensions only.</p>
<p>Overrides MLP_SR’s switch_to_equation to handle pruned architectures correctly.
Active dimensions use their discovered symbolic expressions, while inactive
dimensions output zeros as enforced by the pruning mask.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>complexity</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)"><em>list</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – Specific complexity levels to use.
If list, maps to active dimensions in order.
If int, uses same complexity for all active dimensions.
If None, uses best overall equation for each active dimension.</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">pruned_mlp</span><span class="o">.</span><span class="n">switch_to_equation</span><span class="p">()</span>  <span class="c1"># Use best equations for all active dimensions</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">pruned_mlp</span><span class="o">.</span><span class="n">switch_to_equation</span><span class="p">(</span><span class="n">complexity</span><span class="o">=</span><span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">7</span><span class="p">])</span>  <span class="c1"># Use complexity 5 for first active dim, 7 for second</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="symtorch.toolkit.Pruning_MLP.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/symtorch/toolkit.html#Pruning_MLP.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#symtorch.toolkit.Pruning_MLP.forward" title="Link to this definition"></a></dt>
<dd><p>Forward pass through the model with pruning mask applied.</p>
<p>Automatically switches between MLP and symbolic equations based on current mode.
When using MLP mode, applies pruning mask to zero out inactive dimensions.
When using symbolic equation mode, evaluates equations only for active dimensions
and outputs zeros for inactive dimensions.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> (<a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.7)"><em>torch.Tensor</em></a>) – Input tensor of shape (batch_size, input_dim)</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>Output tensor of shape (batch_size, initial_dim) with inactive</dt><dd><p>dimensions masked to zero</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.7)">torch.Tensor</a></p>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#ValueError" title="(in Python v3.13)"><strong>ValueError</strong></a> – If symbolic equations require variables not present in input</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<section id="configuration-and-parameters">
<h3>Configuration and Parameters<a class="headerlink" href="#configuration-and-parameters" title="Link to this heading"></a></h3>
</section>
</section>
<section id="pysr-parameters">
<h2>PySR Parameters<a class="headerlink" href="#pysr-parameters" title="Link to this heading"></a></h2>
<p>The <code class="xref py py-meth docutils literal notranslate"><span class="pre">MLP_SR.interpret()</span></code> method parses in parameters to a <cite>PySRRegressor</cite> class. Please see <a class="reference external" href="https://ai.damtp.cam.ac.uk/pysr/api/">PySR</a> for more details.</p>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="index.html" class="btn btn-neutral float-left" title="Installation" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="demos/getting_started_demo.html" class="btn btn-neutral float-right" title="Getting Started" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright .</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>